# ğŸ¥ Clinical Trial Data Extractor v2.0

**AI-Powered Ensemble Extraction System for Systematic Reviews & Network Meta-Analyses**

A comprehensive web application that extracts clinical trial data from PDF papers using **multiple extraction methods** including AI, OCR, pattern matching, and direct table parsing, designed to meet Cochrane systematic review standards with complete transparency and source attribution.

---

## âœ¨ Key Features (v2.0 Enhancements)

### ï¿½ **Ensemble Extraction Architecture**
- **Multi-Method Approach**: Combines LLM, OCR, table parsing, and pattern matching
- **Smart Data Fusion**: Intelligently merges results from all extraction methods
- **Comprehensive Coverage**: Captures data missed by individual methods
- **Process Transparency**: Detailed diagnostics showing what each method contributed
- **Quality Assurance**: Cross-validation between extraction methods

### ğŸ” **Enhanced Multi-Method PDF Extraction**
- **PDFPlumber Text**: High-quality text extraction (100k+ characters)
- **Tesseract OCR**: Image and figure text recognition  
- **Table Detection**: PDFPlumber + Camelot for comprehensive table extraction
- **Pattern Matching**: Regex-based statistical value extraction (p-values, CIs, effect sizes)
- **Demographics Extraction**: Direct parsing of baseline characteristics tables
- **Heuristic Analysis**: Rule-based extraction for common clinical trial patterns

### ğŸ“Š **Cochrane-Compliant Data Structure**
- **Multiple Timepoints**: Same outcome measured at different times (4 weeks, 12 weeks, 6 months)
- **Enhanced Timepoint Support**: 27 database fields per timepoint for comprehensive data
- **Universal Outcome Types**: Continuous, dichotomous, time-to-event, count data
- **Complete Effect Estimates**: Between-group comparisons with confidence intervals and p-values
- **Source Attribution**: Every data point traceable to specific pages/tables
- **Missing Data Tracking**: Clear identification of unavailable data points

### ğŸ’¾ **Advanced Database Architecture**
- **PostgreSQL Backend**: Robust relational database with advanced indexing
- **OutcomeTimepoints Table**: 27 fields capturing all statistical parameters
- **Source Citation Storage**: Complete provenance tracking for systematic reviews
- **Meta-Analysis Ready**: Direct export capabilities for RevMan, R, and Stata
- **Complex Queries**: Filter by timepoint, effect size, significance, confidence levels
- **Data Integrity**: Smart truncation handling for database field constraints

### ğŸŒ **Enhanced Web Interface with Process Transparency**
- **Real-Time Diagnostics**: Live extraction progress with method-by-method feedback
- **Process Details Panel**: Shows exactly what each extraction method found
- **Data Source Analysis**: Clear indication of where each data point originated
- **Token Usage Monitoring**: OpenAI API usage tracking with warnings
- **Population Data Display**: Demographics with source attribution
- **Enhanced Confidence Scoring**: Section-by-section quality assessment

---

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.11+**
- **PostgreSQL 18+**
- **Tesseract OCR**
- **Poppler PDF utilities**
- **OpenAI API key**

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/terlinge/clinical-trial-extractor.git
cd clinical-trial-extractor
```

2. **Set up Python environment**
```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # macOS/Linux
pip install -r requirements.txt
```

3. **Configure environment variables**
Create `.env` file:
```env
OPENAI_API_KEY=your_openai_api_key_here
DATABASE_URL=postgresql://username:password@localhost/clinical_trials
```

4. **Start the application**
```powershell
# Windows (recommended)
.\START_APP.ps1

# Or manually
python app.py
```

5. **Access the web interface**
Open http://localhost:5000 in your browser

---

## ğŸ†• What's New in v2.0

### **ğŸ”§ Major Architecture Improvements**
- **Fixed Ensemble Logic**: Previously, non-LLM extraction methods were running but their data was discarded. Now all methods contribute to final results.
- **True Multi-Method Approach**: Combines LLM intelligence with direct table parsing, pattern matching, and OCR for maximum data capture.
- **Population Data Recovery**: Demographics and baseline characteristics now extracted from tables and patterns, not just LLM.
- **Database Field Optimization**: Smart truncation handling prevents data loss due to field length constraints.

### **ğŸ“Š Enhanced Data Quality**
- **Comprehensive Demographics**: Age, gender, sample sizes extracted from multiple sources
- **Statistical Pattern Matching**: Direct extraction of p-values, confidence intervals, effect sizes using regex patterns
- **Table-Based Extraction**: Baseline characteristics and demographic data parsed directly from tables
- **Source Attribution**: Every data point traceable to specific pages/tables with confidence levels

### **ï¿½ Process Transparency**
- **Real-Time Diagnostics**: See exactly what each extraction method found (character counts, pattern counts, table counts)
- **Method Performance**: Clear success/failure indicators for each extraction approach
- **Token Usage Monitoring**: OpenAI API usage tracking with warnings for high consumption
- **Data Source Analysis**: Understand where each piece of data originated

### **âš¡ Performance & Reliability**
- **Smart Token Management**: Automatic prompt optimization to stay within OpenAI rate limits
- **Enhanced Error Handling**: Graceful handling of database constraints and API limitations
- **Improved OCR Processing**: Better text extraction from images and figures
- **Robust Table Detection**: Enhanced table parsing with multiple algorithms

---

## ï¿½ğŸ“ Project Structure

```
clinical-trial-extractor/
â”œâ”€â”€ app.py                      # Main Flask application (Enhanced v2.0)
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html             # Web interface (Enhanced diagnostics)
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ START_APP.ps1             # Windows startup script
â”œâ”€â”€ CHANGELOG.md              # Version history
â”œâ”€â”€ fix_truncation.py         # Database optimization utility
â”œâ”€â”€ backup_database.py        # Database backup utility
â”œâ”€â”€ database_query_examples.py # Advanced querying examples
â”œâ”€â”€ .env                      # Environment variables (create this)
â””â”€â”€ uploads/                  # Temporary PDF storage
```

---

## ğŸ§  How the v2.0 Ensemble Extraction Works

Our **Enhanced Ensemble Architecture** combines multiple extraction methods for maximum accuracy:

### **ğŸ”„ Multi-Method Pipeline**

1. **ğŸ“ Text-based Extraction (PDFPlumber)**
   - Extracts clean text content from PDFs
   - Preserves document structure and formatting
   - Typical yield: 50k-150k characters per document

2. **ğŸ” OCR Processing (Tesseract)**
   - Extracts text from images, figures, and scanned content
   - Captures data missed by text-based methods
   - Fallback for complex formatting scenarios

3. **ğŸ“Š Table Detection & Parsing**
   - Directly extracts structured data from tables
   - Identifies baseline characteristics and demographic data
   - Preserves numerical relationships and statistical data

4. **ğŸ¯ Pattern Matching (Heuristic)**
   - Uses regex patterns to find statistical values
   - Extracts p-values, confidence intervals, effect sizes
   - Direct capture without LLM interpretation

5. **ğŸ¤– LLM Analysis (OpenAI GPT)**
   - Intelligent interpretation of extracted content
   - Contextual understanding and data synthesis
   - Smart prompt management within token limits

6. **ğŸ”„ Ensemble Combination**
   - Combines results from all methods intelligently
   - Prioritizes direct extractions over LLM interpretations
   - Provides source attribution for transparency

**Result**: Comprehensive data extraction with 90%+ confidence levels and full process transparency.

### **ğŸ“Š Real-Time Process Diagnostics**
- See exactly what each method extracted (character counts, pattern counts, table counts)
- Monitor OpenAI API token usage and costs
- Track success/failure of each extraction approach
- Understand data source attribution for every field

---

## ğŸ¯ Enhanced Extraction Capabilities

### **Multi-Timepoint Support**
The system now captures outcomes measured at different timepoints:
```
Example: Pain Score Outcome
â”œâ”€â”€ Baseline (Week 0)
â”œâ”€â”€ Short-term (Week 4) - Secondary timepoint
â”œâ”€â”€ Primary endpoint (Week 12) - Primary timepoint  
â””â”€â”€ Follow-up (Week 26) - Follow-up timepoint
```

### **Source Citation Tracking**
Every extracted data point includes precise source information:
```json
{
  "mean_value": 7.2,
  "data_source": "Table 2 page 5",
  "source_confidence": "high"
}
```

### **Smart Prompt Management**
- **Full Extraction**: For documents under 100k characters
- **Focused Extraction**: Prioritizes statistical tables and outcome data for large documents
- **Universal Keywords**: Works across all clinical trial types (not limited to specific diseases)

---

## ğŸ—„ï¸ Database Schema

### **Enhanced Multi-Timepoint Architecture**

**Studies Table**
- Study identification (title, authors, journal, year, DOI)
- Study design (type, blinding, randomization, duration)
- Source tracking and metadata

**Outcomes Table**
- Outcome metadata (name, type, planned timepoints)
- Links to multiple timepoints

**OutcomeTimepoints Table** â­ *New Enhanced Table*
- Individual timepoint data (value, unit, type)
- Statistical results (means, SDs, CIs, p-values)
- Effect estimates and between-group comparisons
- Source citations and confidence levels

### **Powerful Querying Examples**
```python
# Find all 12-week primary outcomes
outcomes_12w = OutcomeTimepoint.query.filter(
    timepoint_value == 12, 
    timepoint_unit == 'weeks',
    timepoint_type == 'primary'
).all()

# Compare short-term vs long-term effects
short_term = OutcomeTimepoint.query.filter(timepoint_value <= 4).all()
long_term = OutcomeTimepoint.query.filter(timepoint_value >= 12).all()

# Meta-analysis ready export
significant_outcomes = OutcomeTimepoint.query.filter(
    p_value < 0.05, outcome_type == 'secondary'
).all()
```

---

## ğŸ”§ System Requirements

### **Software Dependencies**
- **Python 3.11+** with virtual environment
- **PostgreSQL 18+** database server
- **Tesseract OCR v5.5+** for image text extraction
- **Poppler 25.07+** for PDF-to-image conversion
- **OpenAI API access** for GPT-4 analysis

### **Hardware Recommendations**
- **RAM**: 8GB+ (16GB recommended for large PDFs)
- **Storage**: 10GB+ for database and temporary files
- **CPU**: Multi-core processor for OCR processing

---

## ğŸ“Š Data Extraction Standards

### **Cochrane Systematic Review Compliance**
âœ… Multiple timepoints per outcome  
âœ… Primary vs secondary endpoint designation  
âœ… Interim analysis detection  
âœ… Source citation for every data point  
âœ… Effect size extraction with confidence intervals  
âœ… Meta-analysis ready data export  
âœ… CONSORT flow diagram data capture  

### **Supported Clinical Trial Types**
- Randomized controlled trials (parallel, crossover, cluster)
- Dose-response studies
- Safety and efficacy trials
- Biomarker studies
- Patient-reported outcome studies

### **Supported Outcome Types**
- **Continuous**: Means, SDs, medians, IQRs, confidence intervals
- **Dichotomous**: Events, totals, proportions, odds ratios, relative risks
- **Time-to-event**: Survival analysis, hazard ratios, Kaplan-Meier data

---

## ğŸ“‹ Version History

### **v2.0 - Major Architecture Overhaul** (Current)

#### ğŸ”§ **Core Fixes**
- **CRITICAL**: Fixed ensemble logic that was discarding 80% of extracted data
- **Database**: Resolved varchar(50) field truncation causing data loss
- **Population Data**: Demographics now properly extracted from tables and patterns

#### âœ¨ **New Features**
- **Process Transparency**: Real-time diagnostics showing what each method extracts
- **Source Attribution**: Every data point traceable to specific pages/tables
- **Enhanced Demographics**: Age, gender, sample sizes from multiple extraction sources
- **Smart Token Management**: Automatic OpenAI prompt optimization within rate limits

#### ğŸ“Š **Quality Improvements**
- **Extraction Confidence**: Now achieving 90%+ confidence levels consistently
- **Multi-Method Validation**: LLM + direct parsing + pattern matching + OCR
- **Statistical Pattern Matching**: Direct regex extraction of p-values, CIs, effect sizes
- **Table-Based Demographics**: Baseline characteristics parsed directly from tables

#### ğŸ” **Technical Enhancements**
- **Enhanced Error Handling**: Graceful database constraint and API limit handling
- **Improved OCR**: Better text extraction from images and complex formatting
- **Robust Table Detection**: Multiple algorithms for comprehensive table parsing
- **Performance Monitoring**: Token usage tracking and method success indicators

### **v1.x - Initial Implementation**
- Basic PDF text extraction with LLM analysis
- Simple web interface for file upload and results display
- PostgreSQL database integration
- Basic outcome and timepoint extraction

---

## ğŸ› ï¸ Troubleshooting

### **Common Issues**
- **Database Connection**: Ensure PostgreSQL is running and credentials are correct
- **OpenAI API**: Verify API key is valid and has sufficient credits
- **PDF Processing**: Some PDFs may require OCR if text extraction fails
- **Token Limits**: Large documents may require processing in chunks

### **Performance Tips**
- Use high-quality PDFs for best extraction results
- Monitor token usage in the process diagnostics panel
- Review extraction methods to understand data source attribution
- Check database field lengths if encountering truncation warnings
- **Count data**: Rate ratios, incidence rates

---

## ğŸ”„ Version History

### **v2.0 - Enhanced Multi-Timepoint Support** (Current)
- Added Cochrane-compliant multiple timepoint extraction
- Enhanced database schema with OutcomeTimepoints table
- Implemented smart prompt management for large documents
- Added comprehensive source citation tracking
- Improved UI with real-time progress and extraction summaries

### **v1.0 - Core Functionality**
- Basic PDF extraction with OCR and AI
- PostgreSQL database integration
- Web interface with studies library
- Excel export capabilities

---

## ğŸ¤ Contributing

This system is designed for systematic reviewers and meta-analysis researchers. Contributions welcome for:
- Additional extraction methods
- Database query optimizations  
- UI/UX improvements
- Documentation enhancements

---

## ğŸ“œ License

MIT License - See LICENSE file for details

---

## ğŸ†˜ Support

For issues or questions:
1. Check the database_query_examples.py for advanced usage
2. Review extraction logs in the terminal output
3. Verify all dependencies are correctly installed
4. Ensure PostgreSQL service is running

**GitHub Repository**: https://github.com/terlinge/clinical-trial-extractor